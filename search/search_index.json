{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"V\u00edtejte v dokumentaci pro projekt Komprese stromov\u00fdch struktur \ud83c\udf33","text":""},{"location":"#cil-projektu","title":"\ud83d\ude80 C\u00edl projektu","text":"<p>C\u00edlem tohoto projektu je efektivn\u011b komprimovat stromov\u00e9 struktury generovan\u00e9 anal\u00fdzou textov\u00fdch v\u011bt. Tento projekt zahrnuje detekci vzorc\u016f, jejich kompresi a optimalizaci pro pr\u00e1ci s rozs\u00e1hl\u00fdmi daty.</p> <p></p>"},{"location":"#hlavni-temata","title":"\ud83d\uddc2\ufe0f Hlavn\u00ed t\u00e9mataAnal\u00fdza text\u016fDetekce vzorc\u016fOptimalizace v\u00fdkonu","text":"<p>Prozkoumejte kl\u00ed\u010dov\u00e9 oblasti projektu. Kliknut\u00edm na jednotliv\u00e9 karty se dozv\u00edte v\u00edce o ka\u017ed\u00e9 funkci.</p> <p>Generov\u00e1n\u00ed stromov\u00fdch struktur z textov\u00fdch v\u011bt pro dal\u0161\u00ed zpracov\u00e1n\u00ed a anal\u00fdzu.</p> <p>Identifikace vzorc\u016f pro efektivn\u00ed kompresi stromov\u00fdch dat.</p> <p>Zpracov\u00e1n\u00ed a komprese velk\u00fdch datov\u00fdch soubor\u016f efektivn\u00edm zp\u016fsobem.</p> <p>Prozkoumejte detaily v sekc\u00edch n\u00ed\u017ee pro v\u00edce informac\u00ed o jednotliv\u00fdch t\u00e9matech projektu.</p>"},{"location":"#jak-tento-projekt-pomaha","title":"\ud83c\udfd7\ufe0f Jak tento projekt pom\u00e1h\u00e1","text":"<p>Na\u0161\u00edm c\u00edlem je vytvo\u0159it syst\u00e9m, kter\u00fd bude:</p> <ul> <li>Flexibiln\u00ed: Umo\u017en\u00ed roz\u0161i\u0159ov\u00e1n\u00ed o nov\u00e9 kompresn\u00ed metody.</li> <li>Modul\u00e1rn\u00ed: Usnad\u0148uje p\u0159id\u00e1n\u00ed nov\u00fdch funkc\u00ed a roz\u0161i\u0159itelnost.</li> <li>Efektivn\u00ed: Optimalizov\u00e1no pro pr\u00e1ci s velk\u00fdmi objemy dat a stromov\u00fdmi strukturami.</li> </ul>    Projekt vytvo\u0159en\u00fd pro optimalizaci anal\u00fdzy textov\u00fdch dat a kompresi stromov\u00fdch struktur."},{"location":"architecture/","title":"Architektura syst\u00e9mu","text":""},{"location":"architecture/#modularni-struktura","title":"\ud83c\udfdb\ufe0f Modul\u00e1rn\u00ed struktura","text":"<p>Syst\u00e9m je rozd\u011blen do n\u011bkolika modul\u016f, zaji\u0161\u0165uj\u00edc\u00edch flexibilitu a efektivitu.</p>"},{"location":"architecture/#analyza-textu","title":"\ud83d\udce6 Anal\u00fdza textu","text":"<p>Modul pro syntaktickou anal\u00fdzu a generov\u00e1n\u00ed stromov\u00fdch struktur z text\u016f.</p> <ul> <li>V\u00fdstupy: Generovan\u00e9 stromov\u00e9 struktury.</li> <li>Pou\u017eit\u00e9 technologie: .NET</li> </ul>"},{"location":"architecture/#detekce-vzorcu","title":"\ud83e\udde0 Detekce vzorc\u016f","text":"<p>Tento modul identifikuje opakuj\u00edc\u00ed se vzory ve stromov\u00fdch struktur\u00e1ch, kter\u00e9 lze komprimovat.</p> <ul> <li>V\u00fdstupy: Seznam vzorc\u016f pro kompresi.</li> <li>Pou\u017eit\u00e9 technologie: Algoritmy pro detekci vzorc\u016f.</li> </ul>"},{"location":"architecture/#kompresni-algoritmy","title":"\u2699\ufe0f Kompresn\u00ed algoritmy","text":"<p>Implementace kompresn\u00edch metod pro optimalizaci stromov\u00fdch struktur.</p> <ul> <li>Typy algoritm\u016f: Huffmanovo k\u00f3dov\u00e1n\u00ed, LZW.</li> <li>V\u00fdstupy: Komprimovan\u00e9 datov\u00e9 struktury.</li> </ul> <p>Tip: Ka\u017ed\u00fd modul je navr\u017een pro snadnou roz\u0161i\u0159itelnost a testov\u00e1n\u00ed nov\u00fdch metod.</p>"},{"location":"architecture/#vyhody-modularni-struktury","title":"\ud83d\udca1 V\u00fdhody modul\u00e1rn\u00ed struktury","text":"<ul> <li>Flexibilita: Snadno p\u0159id\u00e1v\u00e1te nov\u00e9 moduly.</li> <li>\u0160k\u00e1lovatelnost: Podporuje pr\u00e1ci s r\u016fzn\u00fdmi velikostmi dat.</li> <li>Paralelizace: Ka\u017ed\u00fd modul lze paralelizovat pro zrychlen\u00ed v\u00fdpo\u010dt\u016f.</li> </ul>"},{"location":"journal/","title":"\ud83d\udcdd Journal - Komprese stromov\u00fdch struktur","text":"<p>V tomto den\u00edku dokumentuji postup a experimenty, kter\u00e9 prov\u00e1d\u00edm p\u0159i v\u00fdvoji metody pro kompresi stromov\u00fdch struktur v r\u00e1mci m\u00e9ho projektu. C\u00edlem je optimalizovat zp\u016fsob, jak\u00fdm jsou syntaktick\u00e9 stromy reprezentov\u00e1ny, aby bylo mo\u017en\u00e9 efektivn\u011bji ukl\u00e1dat a zpracov\u00e1vat jazykov\u00e1 data.</p>"},{"location":"journal/#cil-projektu","title":"\ud83c\udfaf C\u00edl projektu","text":"<p>Projekt se zam\u011b\u0159uje na v\u00fdvoj a testov\u00e1n\u00ed r\u016fzn\u00fdch metod pro kompresi syntaktick\u00fdch strom\u016f, kter\u00e9 jsou v\u00fdsledkem anal\u00fdzy textu. V\u011bnuji se zkoum\u00e1n\u00ed r\u016fzn\u00fdch n\u00e1stroj\u016f pro dependency parsing, zpracov\u00e1n\u00ed textu a tvorb\u011b kompresn\u00edch algoritm\u016f, jako je gramatick\u00e1 komprese nebo metoda RePair.</p>"},{"location":"journal/#jak-denik-pomaha","title":"\ud83d\udcd3 Jak den\u00edk pom\u00e1h\u00e1","text":"<p>Ka\u017ed\u00fd z\u00e1pis v den\u00edku se zam\u011b\u0159uje na konkr\u00e9tn\u00ed denn\u00ed pokrok, nov\u00e9 v\u00fdzvy, \u0159e\u0161en\u00ed a testov\u00e1n\u00ed nov\u00fdch metod. Je to pro m\u011b zp\u016fsob, jak sledovat v\u00fdvoj projektu krok za krokem a z\u00e1rove\u0148 poskytnout ostatn\u00edm n\u00e1hled na to, jak se projekt vyv\u00edj\u00ed.</p> <p>Z\u00e1pisky obsahuj\u00ed:</p> <ul> <li>\ud83d\udd2c Experimenty s r\u016fzn\u00fdmi n\u00e1stroji pro syntaktickou anal\u00fdzu.</li> <li>\ud83e\udde9 Testov\u00e1n\u00ed metod komprese, jako je gramatick\u00e1 komprese a RePair.</li> <li>\u26a0\ufe0f Probl\u00e9my, na kter\u00e9 jsem narazil p\u0159i implementaci, a zp\u016fsoby, jak je \u0159e\u0161it.</li> <li>\ud83d\ude80 Pl\u00e1ny do budoucna, jak projekt posunout d\u00e1l.</li> </ul> <p>Ka\u017ed\u00fd z\u00e1pis je podrobn\u00fd a dokumentuje jak technick\u00e9 kroky, tak teoretick\u00e9 \u00favahy a rozhodnut\u00ed.</p>"},{"location":"journal/#prozkoumejte-jednotlive-zaznamy","title":"\ud83d\udd0e Prozkoumejte jednotliv\u00e9 z\u00e1znamy","text":"<p>Pokud m\u00e1te z\u00e1jem o podrobnosti, m\u016f\u017eete si prohl\u00e9dnout jednotliv\u00e9 z\u00e1pisky z den\u00edku podle data. Ka\u017ed\u00fd z\u00e1pis je zam\u011b\u0159en na konkr\u00e9tn\u00ed f\u00e1zi v\u00fdvoje a \u0159e\u0161en\u00ed, kter\u00e1 jsem v dan\u00fd den \u0159e\u0161il.</p> <ul> <li>\ud83d\udcc5 2025-02-19</li> <li>\ud83d\udcc5 2025-02-20</li> <li>\ud83d\udcc5 2025-02-23</li> </ul> <p>Tento den\u00edk je nejen z\u00e1znamem pro m\u011b, ale tak\u00e9 zp\u016fsobem, jak sd\u00edlet moje pokroky s ostatn\u00edmi a z\u00edskat zp\u011btnou vazbu na implementovan\u00e9 metody.</p>"},{"location":"requirements/","title":"Po\u017eadavky na syst\u00e9m","text":""},{"location":"requirements/#funkcni-pozadavky","title":"\u2699\ufe0f Funk\u010dn\u00ed po\u017eadavky","text":"<ul> <li>Anal\u00fdza textu: Syst\u00e9m mus\u00ed generovat stromov\u00e9 struktury.</li> <li>Detekce vzorc\u016f: Identifikace opakuj\u00edc\u00edch se vzorc\u016f ve stromov\u00fdch datech.</li> <li>Kompresn\u00ed algoritmy: Aplikace kompresn\u00edch metod.</li> <li>Dekomprese: Obnoven\u00ed komprimovan\u00fdch strom\u016f.</li> </ul>"},{"location":"requirements/#systemove-pozadavky","title":"\ud83d\udccb Syst\u00e9mov\u00e9 po\u017eadavky","text":"Komponenta Po\u017eadavek Hardware 8 GB RAM, v\u00edce-j\u00e1drov\u00fd procesor OS Linux, Windows, macOS"},{"location":"requirements/#ne-funkcni-pozadavky","title":"\ud83d\udee0\ufe0f Ne-funk\u010dn\u00ed po\u017eadavky","text":"<ul> <li>V\u00fdkon: Schopnost zpracov\u00e1vat soubory o velikosti n\u011bkolika GB.</li> <li>Modularita: Snadn\u00e1 roz\u0161i\u0159itelnost o nov\u00e9 moduly.</li> <li>Bezpe\u010dnost: Zaji\u0161t\u011bn\u00ed ochrany dat.</li> </ul> <p>Pozn\u00e1mka: Tyto po\u017eadavky zaji\u0161\u0165uj\u00ed v\u00fdkon a flexibilitu pro r\u016fzn\u00e9 velikosti dat.</p>"},{"location":"journal/2025-02-19/","title":"Journal Entry - 2025-02-19","text":"<p>Na za\u010d\u00e1tku jsem za\u010dal zkoumat r\u016fzn\u00e9 zp\u016fsoby, jak strojov\u011b sestavit stromov\u00e9 struktury v\u011bt nebo jednotliv\u00fdch slov. Jako prvn\u00ed jsem se zam\u011b\u0159il na projekt MorphoDiTa, kter\u00fd slou\u017e\u00ed k taggingu (tj. p\u0159i\u0159azov\u00e1n\u00ed slovn\u00edm tvar\u016fm jejich gramatick\u00fdch kategori\u00ed, jako je slovn\u00ed druh, p\u00e1d nebo osoba) a k lemmatizaci (tj. p\u0159evodu slov na jejich z\u00e1kladn\u00ed tvar \u2013 lemma).</p> <p>Pro experimenty jsem vytvo\u0159il jednoduch\u00fd framework v jazyce C#, ve kter\u00e9m pomoc\u00ed z\u00e1kladn\u00edch p\u0159\u00edkaz\u016f testuji tagger a lemmatizaci. Zkoum\u00e1m tak\u00e9, zda by \u010d\u00e1sti lemmatiza\u010dn\u00edho derivativn\u00edho stromu mohly b\u00fdt vyu\u017eity ke kompresi textu.</p> <p>U men\u0161\u00edch soubor\u016f se m\u016f\u017ee st\u00e1t, \u017ee se velikost sp\u00ed\u0161e zv\u00fd\u0161\u00ed, ale u v\u011bt\u0161\u00edch text\u016f by naopak mohla klesnout \u2013 to v\u0161ak mus\u00edm experiment\u00e1ln\u011b ov\u011b\u0159it. V t\u00e9to f\u00e1zi projektu hled\u00e1m vhodn\u00fd zp\u016fsob, jak efektivn\u011b sestavit stromov\u00e9 struktury na z\u00e1klad\u011b z\u00edskan\u00fdch analytick\u00fdch dat. Tagging se zat\u00edm jev\u00ed jako nejlep\u0161\u00ed p\u0159\u00edstup, ale pot\u0159ebuji naj\u00edt optim\u00e1ln\u00ed krit\u00e9ria pro jejich konstrukci.</p> <p>Na\u0161el jsem Dependency Parser Parsito, kter\u00fd by mohl dok\u00e1zat vytvo\u0159it strom. Mus\u00edm se je\u0161t\u011b v\u00edce nau\u010dit jak funguje NLP a tyto algoritmy.</p> <p>Parsito bohu\u017eel nefunguje na architektur\u00e1ch ARM64, z\u00e1rove\u0148 je dlouhou dobu nepou\u017e\u00edvan\u00fd. Release co se mi poda\u0159ilo st\u00e1hnout je z roku 2016.</p> <p>D\u00e1le jsem narazil na StanfordNLP, kter\u00fd je moment\u00e1ln\u011b ozna\u010den\u00fd za deprecated, tud\u00ed\u017e pro m\u011b nejsp\u00ed\u0161 nepou\u017eiteln\u00fd???</p> <p>~~Z\u00e1rove\u0148 m\u011b napadlo, pokud se mi nepoda\u0159\u00ed rozjet model pro dependency parsing lok\u00e1ln\u011b,~~ mohl ~~bych vyu\u017e\u00edt alespo\u0148 n\u011bjak\u00e9 REST API.~~ REST API nen\u00ed podporovan\u00e9.</p> <p>Na\u0161el jsem knihovnu UDPipe, kter\u00e1 m\u00e1 wrapper p\u0159\u00edmo pro C#, tak\u017ee by mohla b\u00fdt jednodu\u0161e pou\u017eiteln\u00e1.</p>"},{"location":"journal/2025-02-20/","title":"Journal Entry - 2025-02-20","text":"<p>Pomoc\u00ed UDPipe 1 a modelu pro angli\u010dtinu se mi poda\u0159ilo \u00fasp\u011b\u0161n\u011b sestavit syntaktick\u00fd strom z b\u011b\u017en\u00e9ho anglick\u00e9ho textu. Projekt byl pom\u011brn\u011b n\u00e1ro\u010dn\u00fd, ale nakonec se mi poda\u0159ilo dos\u00e1hnout spr\u00e1vn\u00fdch v\u00fdsledk\u016f.</p> <p>B\u011bhem pr\u00e1ce jsem narazil na probl\u00e9m s tokenizac\u00ed, kter\u00fd ovliv\u0148oval kvalitu dependency parsingu a vedl k nedostate\u010dn\u011b p\u0159esn\u00fdm v\u00fdstup\u016fm. Po n\u011bkolika experimentech se mi v\u0161ak poda\u0159ilo probl\u00e9m vy\u0159e\u0161it a z\u00edskat spr\u00e1vnou strukturu stromu.</p> <p>Nyn\u00ed se zam\u011b\u0159\u00edm na:</p> <ol> <li>Skl\u00e1d\u00e1n\u00ed v\u011bt do stromov\u00fdch struktur.</li> <li>Testov\u00e1n\u00ed r\u016fzn\u00fdch metod komprese pro syntaktick\u00e9 stromy.</li> <li>Porovn\u00e1n\u00ed a anal\u00fdzu v\u00fdsledk\u016f \u2013 nap\u0159\u00edklad ve srovn\u00e1n\u00ed s jin\u00fdmi metodami komprese.</li> </ol> <p>C\u00edlem je optimalizovat reprezentaci syntaktick\u00fdch strom\u016f, aby bylo mo\u017en\u00e9 jazykov\u00e1 data efektivn\u011b ukl\u00e1dat a zpracov\u00e1vat.</p> <p>Pou\u017eil jsem UDPipe 1, proto\u017ee:</p> <ul> <li>UDPipe 2 je st\u00e1le experiment\u00e1ln\u00ed a napsan\u00fd v Pythonu.</li> <li>UDPipe 3, kter\u00fd by m\u011bl op\u011bt nab\u00eddnout p\u0159\u00edv\u011btiv\u00e9 API a bindingy, je teprve ve v\u00fdvoji.</li> </ul>"},{"location":"journal/2025-02-23/","title":"Journal Entry - 2025-02-23","text":""},{"location":"journal/2025-02-23/#1-sestaveni-stromove-struktury","title":"1. Sestaven\u00ed stromov\u00e9 struktury","text":"<p>Po \u00fasp\u011b\u0161n\u00e9m testov\u00e1n\u00ed se mi poda\u0159ilo sestavit stromovou strukturu z textov\u00fdch dat. Tento proces zahrnoval:</p> <ul> <li>Parsov\u00e1n\u00ed vstupn\u00edho textu.</li> <li>Vytvo\u0159en\u00ed stromov\u00e9 struktury, kde ka\u017ed\u00fd uzel obsahuje ur\u010ditou hodnotu z textu.</li> <li>Lev\u00fd a prav\u00fd podstrom byly generov\u00e1ny na z\u00e1klad\u011b specifick\u00fdch pravidel vych\u00e1zej\u00edc\u00edch z textov\u00e9ho form\u00e1tu.</li> </ul>"},{"location":"journal/2025-02-23/#2-komprese-stromu-pomoci-gramatiky","title":"2. Komprese stromu pomoc\u00ed gramatiky","text":"<p>Po sestaven\u00ed stromov\u00e9 struktury jsem provedl kompresi pomoc\u00ed gramatiky. Tento postup spo\u010d\u00edval v:</p> <ul> <li>Nahradit opakuj\u00edc\u00ed se podstromy jedine\u010dn\u00fdmi pravidly.</li> <li>Redukce velikosti stromu, kde ka\u017ed\u00fd unik\u00e1tn\u00ed podstrom z\u00edskal vlastn\u00ed pravidlo (nap\u0159. R1, R2 atd.), co\u017e vedlo k v\u00fdrazn\u00e9 kompresi struktury.</li> </ul>"},{"location":"journal/2025-02-23/#3-dalsi-mozny-krok-pouziti-metody-repair","title":"3. Dal\u0161\u00ed mo\u017en\u00fd krok: Pou\u017eit\u00ed metody RePair","text":"<p>Vzhledem k \u00fasp\u011b\u0161nosti gramatick\u00e9 komprese bych r\u00e1d pokra\u010doval v testov\u00e1n\u00ed metody RePair. Tato metoda je zn\u00e1m\u00e1 svou efektivitou p\u0159i:</p> <ul> <li>Hled\u00e1n\u00ed opakuj\u00edc\u00edch se vzorc\u016f v textov\u00fdch datech.</li> <li>Nahrazen\u00ed t\u011bchto vzorc\u016f symboly, co\u017e vede k dal\u0161\u00ed redukci velikosti dat.</li> </ul> <p>Pl\u00e1nuji implementovat metodu RePair a testovat jej\u00ed vliv na kompresi stromu, abych zjistil, zda poskytne lep\u0161\u00ed v\u00fdsledky ne\u017e aktu\u00e1ln\u00ed metoda gramatick\u00e9 komprese.</p>"},{"location":"journal/2025-02-23/#4-problem-se-serazenim-dat-v-leve-a-prave-vetvi","title":"4. Probl\u00e9m se se\u0159azen\u00edm dat v lev\u00e9 a prav\u00e9 v\u011btvi","text":"<p>Jedn\u00edm z probl\u00e9m\u016f, na kter\u00e9 jsem narazil, je pot\u0159eba se\u0159azen\u00ed dat v obou v\u011btv\u00edch stromu (lev\u00e9 i prav\u00e9). Tento probl\u00e9m m\u016f\u017ee ovlivnit v\u00fdsledky komprese, proto\u017ee:</p> <ul> <li>Neoptimalizovan\u00e9 se\u0159azen\u00ed dat m\u016f\u017ee v\u00e9st k ztr\u00e1t\u011b kompresn\u00ed \u00fa\u010dinnosti.</li> <li>Moment\u00e1ln\u011b nejsem \u00fapln\u011b jist\u00fd, jak spr\u00e1vn\u011b data uspo\u0159\u00e1dat, aby komprese prob\u00edhla co nejefektivn\u011bji.</li> </ul>"},{"location":"journal/2025-02-23/#5-dalsi-kroky","title":"5. Dal\u0161\u00ed kroky","text":"<p>Pro \u0159e\u0161en\u00ed v\u00fd\u0161e uveden\u00e9ho probl\u00e9mu pl\u00e1nuju:</p> <ul> <li>Analyzovat mo\u017en\u00e9 p\u0159\u00edstupy k se\u0159azen\u00ed dat, kter\u00e9 by mohly optimalizovat kompresi.</li> <li>Experimentovat s r\u016fzn\u00fdmi metodami uspo\u0159\u00e1d\u00e1n\u00ed dat ve strom\u011b pro dosa\u017een\u00ed co nejlep\u0161\u00edho v\u00fdsledku.</li> </ul>"},{"location":"journal/2025-03-10/","title":"\ud83d\udcc5 2025-02-25 - V\u00fdzkum a implementace algoritm\u016f pro kompresi stromov\u00fdch struktur","text":"<p>Dnes jsem se zam\u011b\u0159il na implementaci a v\u00fdzkum r\u016fzn\u00fdch existuj\u00edc\u00edch algoritm\u016f pro kompresi stromov\u00fdch struktur. Prozkoumal jsem t\u0159i hlavn\u00ed algoritmy: DictionaryTreeCompression, FrequentSubtreeCompression a RePairTreeCompressor. Ka\u017ed\u00fd z t\u011bchto algoritm\u016f m\u00e1 sv\u00e9 v\u00fdhody a specifick\u00e9 vyu\u017eit\u00ed v z\u00e1vislosti na druhu dat, kter\u00e1 se komprimuj\u00ed. Tento v\u00fdzkum mi pomohl l\u00e9pe pochopit, jak ka\u017ed\u00fd z t\u011bchto p\u0159\u00edstup\u016f funguje a jak je mo\u017en\u00e9 je vyu\u017e\u00edt pro optimalizaci komprese strom\u016f ve sv\u00e9m projektu.</p>"},{"location":"journal/2025-03-10/#algoritmy-pro-kompresi-stromovych-struktur","title":"\ud83d\udcda Algoritmy pro kompresi stromov\u00fdch struktur","text":""},{"location":"journal/2025-03-10/#1-dictionarytreecompression","title":"1. DictionaryTreeCompression","text":"<p>Tento algoritmus je zn\u00e1m\u00fd svou efektivitou p\u0159i kompresi dat ve stromov\u00fdch struktur\u00e1ch, p\u0159i\u010dem\u017e je b\u011b\u017en\u011b pou\u017e\u00edv\u00e1n pro kompresi XML dat a dal\u0161\u00edch hierarchick\u00fdch datov\u00fdch form\u00e1t\u016f. Funguje tak, \u017ee vytv\u00e1\u0159\u00ed slovn\u00edk, kter\u00fd obsahuje opakuj\u00edc\u00ed se podstromy. Ka\u017ed\u00fd podstrom je reprezentov\u00e1n kl\u00ed\u010dem ve slovn\u00edku, co\u017e umo\u017e\u0148uje kompresi t\u00edm, \u017ee m\u00edsto opakovan\u00fdch podstrom\u016f se pou\u017e\u00edv\u00e1 pouze jejich kl\u00ed\u010d. Tento p\u0159\u00edstup v\u00fdrazn\u011b sni\u017euje velikost dat, zejm\u00e9na pokud existuj\u00ed rekurentn\u00ed vzory.</p> <p>Mo\u017enosti vyu\u017eit\u00ed: - Tento algoritmus bych mohl pou\u017e\u00edt pro kompresi stromov\u00fdch struktur, kter\u00e9 vykazuj\u00ed vysokou m\u00edru opakov\u00e1n\u00ed v jejich podstrukturoch. - V budoucnu by se mohl uk\u00e1zat jako efektivn\u00ed pro kompresi syntaktick\u00fdch strom\u016f, pokud se budou vyskytovat opakuj\u00edc\u00ed se vzory, nap\u0159\u00edklad v dlouh\u00fdch v\u011bt\u00e1ch nebo textov\u00fdch bloc\u00edch.</p>"},{"location":"journal/2025-03-10/#2-frequentsubtreecompression","title":"2. FrequentSubtreeCompression","text":"<p>Tento algoritmus se zam\u011b\u0159uje na kompresi \u010dast\u00fdch podstrom\u016f, co\u017e znamen\u00e1, \u017ee hled\u00e1 podstromy, kter\u00e9 se vyskytuj\u00ed \u010dasto v cel\u00e9m stromu, a nahrazuje je jedine\u010dn\u00fdmi identifik\u00e1tory. Tento p\u0159\u00edstup je \u010dasto pou\u017e\u00edv\u00e1n v bioinformatice pro kompresi dat, jako jsou filogenetick\u00e9 stromy, a v dal\u0161\u00edch oblastech, kde se \u010dasto opakuj\u00ed ur\u010dit\u00e9 struktury.</p> <p>Mo\u017enosti vyu\u017eit\u00ed: - Tento algoritmus by mohl b\u00fdt u\u017eite\u010dn\u00fd, pokud budu pracovat s rozs\u00e1hl\u00fdmi daty, kde n\u011bkter\u00e9 podstromy nebo vzory struktury stromu mohou b\u00fdt velmi \u010dast\u00e9. - V budoucnu se uk\u00e1\u017ee jako vhodn\u00fd pro kompresi slo\u017eit\u011bj\u0161\u00edch stromov\u00fdch struktur s vysokou m\u00edrou opakov\u00e1n\u00ed, co\u017e je typick\u00e9 pro texty s mnoha podobn\u00fdmi v\u011btami.</p>"},{"location":"journal/2025-03-10/#3-repairtreecompressor","title":"3. RePairTreeCompressor","text":"<p>RePair je algoritmus, kter\u00fd se zam\u011b\u0159uje na nalezen\u00ed opakuj\u00edc\u00edch se vzorc\u016f v datech a jejich nahrazen\u00ed symboly, co\u017e vede k v\u00fdrazn\u00e9 redukci velikosti. Tento algoritmus je obl\u00edben\u00fd pro kompresi text\u016f a XML dat a je zn\u00e1m\u00fd svou efektivitou p\u0159i hled\u00e1n\u00ed a nahrazov\u00e1n\u00ed opakuj\u00edc\u00edch se podstruktur.</p> <p>Mo\u017enosti vyu\u017eit\u00ed: - RePair je vhodn\u00fd pro situace, kdy je pot\u0159eba efektivn\u011b komprimovat velk\u00e9 mno\u017estv\u00ed dat, a to zejm\u00e9na kdy\u017e se v datech nach\u00e1z\u00ed podobn\u00e9 podstruktury. - Tento algoritmus by mohl b\u00fdt jedn\u00edm z kl\u00ed\u010dov\u00fdch n\u00e1stroj\u016f pro moj\u00ed implementaci kompresn\u00edho algoritmu, zejm\u00e9na pokud budu m\u00edt probl\u00e9m s velk\u00fdm mno\u017estv\u00edm opakuj\u00edc\u00edch se vzorc\u016f v syntaktick\u00fdch stromech.</p>"},{"location":"journal/2025-03-10/#implementace-a-experimenty","title":"\ud83d\udee0\ufe0f Implementace a experimenty","text":"<p>V r\u00e1mci implementace jsem se nejprve zam\u011b\u0159il na z\u00e1kladn\u00ed verzi ka\u017ed\u00e9ho algoritmu:</p> <ul> <li> <p>DictionaryTreeCompression: Za\u010dal jsem implementac\u00ed jednoduch\u00e9ho slovn\u00edku pro ukl\u00e1d\u00e1n\u00ed opakuj\u00edc\u00edch se podstrom\u016f. Testoval jsem ho na n\u011bkolika p\u0159\u00edkladech textu, kde jsem hledal opakuj\u00edc\u00ed se fr\u00e1ze.</p> </li> <li> <p>FrequentSubtreeCompression: Tento algoritmus jsem implementoval tak, \u017ee jsem prohled\u00e1val strom a identifikoval podstromy, kter\u00e9 se vyskytovaly \u010dast\u011bji ne\u017e ostatn\u00ed. Tyto podstromy jsem nahradil identifik\u00e1tory.</p> </li> <li> <p>RePairTreeCompressor: Tento algoritmus jsem implementoval s vyu\u017eit\u00edm principu iterativn\u00ed komprese, kde se v ka\u017ed\u00e9 iteraci hledaj\u00ed a nahrazuj\u00ed opakuj\u00edc\u00ed se vzory. Implementace vy\u017eadovala dostate\u010dn\u011b efektivn\u00ed zp\u016fsob, jak zpracov\u00e1vat a ukl\u00e1dat nalezen\u00e9 vzory.</p> </li> </ul>"},{"location":"journal/2025-03-10/#vysledky-a-zhodnoceni","title":"\ud83d\ude80 V\u00fdsledky a zhodnocen\u00ed","text":"<p>B\u011bhem implementace jsem se hodn\u011b nau\u010dil o t\u011bchto algoritmech a jejich v\u00fdhod\u00e1ch:</p> <ul> <li>DictionaryTreeCompression se osv\u011bd\u010dil jako efektivn\u00ed pro kompresi textov\u00fdch strom\u016f, ale je m\u00e9n\u011b efektivn\u00ed p\u0159i zpracov\u00e1n\u00ed strom\u016f s ni\u017e\u0161\u00edmi m\u00edrami opakov\u00e1n\u00ed.</li> <li>FrequentSubtreeCompression je velmi siln\u00fd p\u0159i kompresi dat, kde se vyskytuj\u00ed \u010dast\u00e9 vzory. M\u016f\u017ee b\u00fdt u\u017eite\u010dn\u00fd pro struktury s v\u00fdrazn\u00fdm opakov\u00e1n\u00edm.</li> <li>RePairTreeCompressor se uk\u00e1zal jako nejlep\u0161\u00ed pro moji aplikaci, proto\u017ee je schopn\u00fd naj\u00edt opakuj\u00edc\u00ed se vzory a komprimovat je velmi efektivn\u011b, zejm\u00e9na u velk\u00fdch strom\u016f.</li> </ul>"},{"location":"journal/2025-03-10/#co-dal","title":"\ud83d\udca1 Co d\u00e1l?","text":"<p>V budoucnu bych cht\u011bl:</p> <ul> <li>Porovnat v\u00fdkon t\u011bchto algoritm\u016f na re\u00e1ln\u00fdch datech.</li> <li>Vytvo\u0159it hybridn\u00ed metodu, kter\u00e1 by kombinovala v\u00fdhody jednotliv\u00fdch algoritm\u016f.</li> <li>Testovat na v\u011bt\u0161\u00edch datech, abych zjistil, jak se chovaj\u00ed p\u0159i vy\u0161\u0161\u00ed slo\u017eitosti a v\u011bt\u0161\u00ed velikosti stromu.</li> </ul> <p>Celkov\u011b jsem se nau\u010dil hodn\u011b o tom, jak algoritmy pro kompresi strom\u016f funguj\u00ed a jak je lze aplikovat na r\u016fzn\u00e9 typy dat. Zat\u00edm se mi nejv\u00edce osv\u011bd\u010dil RePair, ale st\u00e1le je prostor pro optimalizace a zlep\u0161en\u00ed.</p>"}]}